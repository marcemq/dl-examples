{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a simple RNN implementation\n",
    "\n",
    "A simple RNN implementation for predicting next char in a sentence as input.\n",
    "\n",
    "This code example was inspired in [A Beginnerâ€™s Guide on Recurrent Neural Networks with PyTorch](https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentences we want our model to output\n",
    "sentences = [\"hey how are you\", \"not so good actually\", \"i hope you get better\"]\n",
    "\n",
    "# Join sentences and extract its unique characters\n",
    "unique_chars = set(\"\".join(sentences))\n",
    "\n",
    "# map integers to chars in unique_chars, and viceversa\n",
    "int2char = dict(enumerate(unique_chars))\n",
    "char2int = {char:ind  for ind, char in int2char.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'g', 1: 'd', 2: 's', 3: 'o', 4: 'n', 5: 'y', 6: 't', 7: 'l', 8: 'a', 9: 'b', 10: 'e', 11: 'i', 12: 'h', 13: 'w', 14: 'u', 15: ' ', 16: 'p', 17: 'r', 18: 'c'}\n"
     ]
    }
   ],
   "source": [
    "print(int2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest string has 21 characters\n",
      "['hey how are you      ', 'not so good actually ', 'i hope you get better']\n"
     ]
    }
   ],
   "source": [
    "# having the longest sequence we're going to pad the rest with \" \" to match such length\n",
    "maxlen = len(max(sentences, key=len))\n",
    "print(\"The longest string has {} characters\".format(maxlen))\n",
    "\n",
    "# simple padding\n",
    "for i in range(len(sentences)):\n",
    "    while len(sentences[i]) < maxlen:\n",
    "        sentences[i] += ' '\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists that will store our input/target sequences, \n",
    "# For input:  the last char does not get into account\n",
    "# For output:  the first  char does not get into account\n",
    "input_seq, target_seq = [], []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    input_seq.append(sentences[i][:-1])\n",
    "    target_seq.append(sentences[i][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey how are you     ', 'not so good actually', 'i hope you get bette']\n",
      "['ey how are you      ', 'ot so good actually ', ' hope you get better']\n"
     ]
    }
   ],
   "source": [
    "print(input_seq)\n",
    "print(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting our sequences to be a sequence of integers\n",
    "for i in range(len(sentences)):\n",
    "    input_seq[i] = [char2int[i_char] for i_char in input_seq[i]]\n",
    "    target_seq[i] = [char2int[i_char] for i_char in target_seq[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 10, 5, 15, 12, 3, 13, 15, 8, 17, 10, 15, 5, 3, 14, 15, 15, 15, 15, 15], [4, 3, 6, 15, 2, 3, 15, 0, 3, 3, 1, 15, 8, 18, 6, 14, 8, 7, 7, 5], [11, 15, 12, 3, 16, 10, 15, 5, 3, 14, 15, 0, 10, 6, 15, 9, 10, 6, 6, 10]]\n"
     ]
    }
   ],
   "source": [
    "print(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:20:3\n"
     ]
    }
   ],
   "source": [
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(sentences)\n",
    "print(\"{}:{}:{}\".format(dict_size, seq_len, batch_size))\n",
    "\n",
    "# helper function: creates array of zeros for each character and replaces the corresponding character index with a 1\n",
    "def oneHotEnc(seq, dict_size, seq_len, batch_size):\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, seq[i][u]] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = oneHotEnc(input_seq, dict_size, seq_len, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RNN model architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# to torch tensors\n",
    "input_seq = torch.from_numpy(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)\n",
    "\n",
    "# Defining our device to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, in_size, out_size, hidden_dim, n_layers):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers   = n_layers\n",
    "        self.rnn        = nn.RNN(in_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc         = nn.Linear(hidden_dim, out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Init hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(x.size(0))\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our SimpleModel\n",
    "model = SimpleModel(in_size=dict_size, out_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100... Loss: 2.4244\n",
      "Epoch: 20/100... Loss: 2.2859\n",
      "Epoch: 30/100... Loss: 1.9903\n",
      "Epoch: 40/100... Loss: 1.6325\n",
      "Epoch: 50/100... Loss: 1.3268\n",
      "Epoch: 60/100... Loss: 1.0473\n",
      "Epoch: 70/100... Loss: 0.7960\n",
      "Epoch: 80/100... Loss: 0.5855\n",
      "Epoch: 90/100... Loss: 0.4299\n",
      "Epoch: 100/100... Loss: 0.3172\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}...'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: given a trained model, it receives a sequence of characters and outputs the predict next character\n",
    "def predict(model, chars):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    chars = np.array([[char2int[c] for c in chars]])\n",
    "    chars = oneHotEnc(chars, dict_size, chars.shape[1], 1)\n",
    "    chars = torch.from_numpy(chars)\n",
    "    chars = chars.to(device)\n",
    "    \n",
    "    out, hidden = model(chars)\n",
    "\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: takes the ground-truth output length and input sequence of characters as arguments\n",
    "# and returns the predicted sentence\n",
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() \n",
    "    start = start.lower()\n",
    "    chars = [char_i for char_i in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for _ in range(size):\n",
    "        char, _ = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i hope you get better'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model, 21, 'I hope')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
